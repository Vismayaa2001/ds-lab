{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56be0b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a6c5560",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38e5f30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,Y_train),(X_valid,Y_valid) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b57b7a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train =X_train .reshape(60000,784).astype('float32')\n",
    "X_valid =X_valid .reshape(10000,784).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "186252a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train /=255\n",
    "X_valid /=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c301e41c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.32941177, 0.7254902 , 0.62352943,\n",
       "       0.5921569 , 0.23529412, 0.14117648, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.87058824, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
       "       0.94509804, 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "       0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.6666667 ,\n",
       "       0.20392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.2627451 , 0.44705883,\n",
       "       0.28235295, 0.44705883, 0.6392157 , 0.8901961 , 0.99607843,\n",
       "       0.88235295, 0.99607843, 0.99607843, 0.99607843, 0.98039216,\n",
       "       0.8980392 , 0.99607843, 0.99607843, 0.54901963, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
       "       0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
       "       0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.3254902 , 0.99215686, 0.81960785, 0.07058824,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.08627451, 0.9137255 ,\n",
       "       1.        , 0.3254902 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.5058824 , 0.99607843, 0.93333334, 0.17254902,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.23137255, 0.9764706 ,\n",
       "       0.99607843, 0.24313726, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.03529412, 0.8039216 ,\n",
       "       0.972549  , 0.22745098, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.49411765, 0.99607843, 0.7137255 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.29411766, 0.9843137 ,\n",
       "       0.9411765 , 0.22352941, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.07450981, 0.8666667 , 0.99607843, 0.6509804 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
       "       0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.14901961, 0.99607843, 0.99607843, 0.3019608 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.12156863, 0.8784314 , 0.99607843,\n",
       "       0.4509804 , 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.52156866, 0.99607843, 0.99607843, 0.20392157, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.23921569, 0.9490196 , 0.99607843,\n",
       "       0.99607843, 0.20392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.4745098 , 0.99607843,\n",
       "       0.8117647 , 0.07058824, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0ff8f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import utils as np_utils\n",
    "n_Classes=10\n",
    "Y_train=keras.utils.np_utils.to_categorical(Y_train,n_Classes)\n",
    "Y_valid=keras.utils.np_utils.to_categorical(Y_valid,n_Classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "290e3864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce1b93c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a90d0d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(64,activation='sigmoid',input_shape=(784,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "579f30c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4050b6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,890\n",
      "Trainable params: 50,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7319fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(loss='mean_squared_error',optimizer=SGD(learning_rate=0.01),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f63f2ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 14:18:27.851011: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "469/469 [==============================] - 15s 4ms/step - loss: 0.0934 - accuracy: 0.0915\n",
      "Epoch 2/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0922 - accuracy: 0.0954\n",
      "Epoch 3/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0914 - accuracy: 0.1286\n",
      "Epoch 4/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0908 - accuracy: 0.1666\n",
      "Epoch 5/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0902 - accuracy: 0.1952\n",
      "Epoch 6/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0898 - accuracy: 0.2166\n",
      "Epoch 7/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0894 - accuracy: 0.2336\n",
      "Epoch 8/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0890 - accuracy: 0.2498\n",
      "Epoch 9/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0887 - accuracy: 0.2653\n",
      "Epoch 10/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0883 - accuracy: 0.2836\n",
      "Epoch 11/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0880 - accuracy: 0.3042\n",
      "Epoch 12/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0877 - accuracy: 0.3250\n",
      "Epoch 13/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0874 - accuracy: 0.3474\n",
      "Epoch 14/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0871 - accuracy: 0.3654\n",
      "Epoch 15/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0867 - accuracy: 0.3785\n",
      "Epoch 16/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0864 - accuracy: 0.3910\n",
      "Epoch 17/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0861 - accuracy: 0.3980\n",
      "Epoch 18/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0858 - accuracy: 0.4045\n",
      "Epoch 19/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0854 - accuracy: 0.4105\n",
      "Epoch 20/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0851 - accuracy: 0.4168\n",
      "Epoch 21/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0847 - accuracy: 0.4216\n",
      "Epoch 22/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0844 - accuracy: 0.4244\n",
      "Epoch 23/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0840 - accuracy: 0.4290\n",
      "Epoch 24/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0837 - accuracy: 0.4330\n",
      "Epoch 25/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0833 - accuracy: 0.4376\n",
      "Epoch 26/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0829 - accuracy: 0.4400\n",
      "Epoch 27/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0825 - accuracy: 0.4440\n",
      "Epoch 28/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0821 - accuracy: 0.4464\n",
      "Epoch 29/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0817 - accuracy: 0.4509\n",
      "Epoch 30/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0813 - accuracy: 0.4549\n",
      "Epoch 31/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0809 - accuracy: 0.4590\n",
      "Epoch 32/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0804 - accuracy: 0.4630\n",
      "Epoch 33/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0800 - accuracy: 0.4669\n",
      "Epoch 34/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0796 - accuracy: 0.4711\n",
      "Epoch 35/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0791 - accuracy: 0.4752\n",
      "Epoch 36/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0786 - accuracy: 0.4801\n",
      "Epoch 37/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0782 - accuracy: 0.4841\n",
      "Epoch 38/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0777 - accuracy: 0.4890\n",
      "Epoch 39/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0772 - accuracy: 0.4934\n",
      "Epoch 40/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0768 - accuracy: 0.4981\n",
      "Epoch 41/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0763 - accuracy: 0.5023\n",
      "Epoch 42/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0758 - accuracy: 0.5064\n",
      "Epoch 43/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0753 - accuracy: 0.5103\n",
      "Epoch 44/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0748 - accuracy: 0.5144\n",
      "Epoch 45/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0743 - accuracy: 0.5181\n",
      "Epoch 46/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0738 - accuracy: 0.5219\n",
      "Epoch 47/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0733 - accuracy: 0.5254\n",
      "Epoch 48/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0728 - accuracy: 0.5282\n",
      "Epoch 49/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0723 - accuracy: 0.5307\n",
      "Epoch 50/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0718 - accuracy: 0.5336\n",
      "Epoch 51/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0713 - accuracy: 0.5372\n",
      "Epoch 52/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0708 - accuracy: 0.5397\n",
      "Epoch 53/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0702 - accuracy: 0.5421\n",
      "Epoch 54/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0697 - accuracy: 0.5450\n",
      "Epoch 55/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0692 - accuracy: 0.5470\n",
      "Epoch 56/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0687 - accuracy: 0.5498\n",
      "Epoch 57/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0682 - accuracy: 0.5530\n",
      "Epoch 58/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0677 - accuracy: 0.5558\n",
      "Epoch 59/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0672 - accuracy: 0.5580\n",
      "Epoch 60/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0667 - accuracy: 0.5602\n",
      "Epoch 61/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0662 - accuracy: 0.5629\n",
      "Epoch 62/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0657 - accuracy: 0.5648\n",
      "Epoch 63/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0652 - accuracy: 0.5669\n",
      "Epoch 64/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0647 - accuracy: 0.5690\n",
      "Epoch 65/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0642 - accuracy: 0.5712\n",
      "Epoch 66/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0638 - accuracy: 0.5741\n",
      "Epoch 67/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0633 - accuracy: 0.5767\n",
      "Epoch 68/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0628 - accuracy: 0.5794\n",
      "Epoch 69/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0623 - accuracy: 0.5822\n",
      "Epoch 70/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0619 - accuracy: 0.5852\n",
      "Epoch 71/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0614 - accuracy: 0.5884\n",
      "Epoch 72/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0610 - accuracy: 0.5913\n",
      "Epoch 73/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0605 - accuracy: 0.5947\n",
      "Epoch 74/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0601 - accuracy: 0.5988\n",
      "Epoch 75/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0596 - accuracy: 0.6024\n",
      "Epoch 76/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0592 - accuracy: 0.6063\n",
      "Epoch 77/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0588 - accuracy: 0.6112\n",
      "Epoch 78/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0584 - accuracy: 0.6159\n",
      "Epoch 79/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0579 - accuracy: 0.6215\n",
      "Epoch 80/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0575 - accuracy: 0.6259\n",
      "Epoch 81/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0571 - accuracy: 0.6303\n",
      "Epoch 82/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0567 - accuracy: 0.6360\n",
      "Epoch 83/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0563 - accuracy: 0.6411\n",
      "Epoch 84/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0559 - accuracy: 0.6463\n",
      "Epoch 85/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0555 - accuracy: 0.6520\n",
      "Epoch 86/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0552 - accuracy: 0.6561\n",
      "Epoch 87/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0548 - accuracy: 0.6612\n",
      "Epoch 88/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0544 - accuracy: 0.6657\n",
      "Epoch 89/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0540 - accuracy: 0.6698\n",
      "Epoch 90/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0537 - accuracy: 0.6739\n",
      "Epoch 91/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0533 - accuracy: 0.6781\n",
      "Epoch 92/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0529 - accuracy: 0.6828\n",
      "Epoch 93/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0526 - accuracy: 0.6859\n",
      "Epoch 94/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0522 - accuracy: 0.6906\n",
      "Epoch 95/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0519 - accuracy: 0.6935\n",
      "Epoch 96/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0515 - accuracy: 0.6975\n",
      "Epoch 97/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0512 - accuracy: 0.7011\n",
      "Epoch 98/150\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0509 - accuracy: 0.7045\n",
      "Epoch 99/150\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0505 - accuracy: 0.7078\n",
      "Epoch 100/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0502 - accuracy: 0.7108\n",
      "Epoch 101/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0499 - accuracy: 0.7137\n",
      "Epoch 102/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0495 - accuracy: 0.7169\n",
      "Epoch 103/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0492 - accuracy: 0.7196\n",
      "Epoch 104/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0489 - accuracy: 0.7225\n",
      "Epoch 105/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0486 - accuracy: 0.7251\n",
      "Epoch 106/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0483 - accuracy: 0.7285\n",
      "Epoch 107/150\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0480 - accuracy: 0.7308\n",
      "Epoch 108/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0477 - accuracy: 0.7336\n",
      "Epoch 109/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0474 - accuracy: 0.7363\n",
      "Epoch 110/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0471 - accuracy: 0.7386\n",
      "Epoch 111/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0468 - accuracy: 0.7415\n",
      "Epoch 112/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0465 - accuracy: 0.7438\n",
      "Epoch 113/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0462 - accuracy: 0.7463\n",
      "Epoch 114/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0459 - accuracy: 0.7484\n",
      "Epoch 115/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0456 - accuracy: 0.7506\n",
      "Epoch 116/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0453 - accuracy: 0.7529\n",
      "Epoch 117/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0450 - accuracy: 0.7555\n",
      "Epoch 118/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0448 - accuracy: 0.7575\n",
      "Epoch 119/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0445 - accuracy: 0.7600\n",
      "Epoch 120/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0442 - accuracy: 0.7620\n",
      "Epoch 121/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0439 - accuracy: 0.7647\n",
      "Epoch 122/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0437 - accuracy: 0.7670\n",
      "Epoch 123/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0434 - accuracy: 0.7691\n",
      "Epoch 124/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0431 - accuracy: 0.7706\n",
      "Epoch 125/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0429 - accuracy: 0.7731\n",
      "Epoch 126/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0426 - accuracy: 0.7756\n",
      "Epoch 127/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0424 - accuracy: 0.7779\n",
      "Epoch 128/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0421 - accuracy: 0.7800\n",
      "Epoch 129/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0419 - accuracy: 0.7823\n",
      "Epoch 130/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0416 - accuracy: 0.7844\n",
      "Epoch 131/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0414 - accuracy: 0.7866\n",
      "Epoch 132/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0411 - accuracy: 0.7884\n",
      "Epoch 133/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0409 - accuracy: 0.7909\n",
      "Epoch 134/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0406 - accuracy: 0.7930\n",
      "Epoch 135/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0404 - accuracy: 0.7946\n",
      "Epoch 136/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0402 - accuracy: 0.7964\n",
      "Epoch 137/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0399 - accuracy: 0.7980\n",
      "Epoch 138/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0397 - accuracy: 0.7995\n",
      "Epoch 139/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0395 - accuracy: 0.8011\n",
      "Epoch 140/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0392 - accuracy: 0.8026\n",
      "Epoch 141/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0390 - accuracy: 0.8047\n",
      "Epoch 142/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0388 - accuracy: 0.8061\n",
      "Epoch 143/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0386 - accuracy: 0.8081\n",
      "Epoch 144/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0384 - accuracy: 0.8095\n",
      "Epoch 145/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0381 - accuracy: 0.8108\n",
      "Epoch 146/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0379 - accuracy: 0.8128\n",
      "Epoch 147/150\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0377 - accuracy: 0.8143\n",
      "Epoch 148/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0375 - accuracy: 0.8160\n",
      "Epoch 149/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0373 - accuracy: 0.8174\n",
      "Epoch 150/150\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0371 - accuracy: 0.8187\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train,Y_train,batch_size=128,epochs=150,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee4bb903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('logisticregression', LogisticRegression(random_state=0))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, Y = fetch_openml(data_id=1464, return_X_y=True)\n",
    "X_train, X_valid, Y_train,Y_valid = train_test_split(X, Y, stratify=Y)\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), LogisticRegression(random_state=0))\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8caa6766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "Y_pred = clf.predict(X_valid)\n",
    "cm = confusion_matrix(Y_valid, Y_pred)\n",
    "\n",
    "cm_display = ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa6bd4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
